# temp-repo

æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ [InstantPure (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒªãƒã‚¸ãƒˆãƒª)](https://github.com/antony090/InstantPure) ã®ã‚³ãƒ¼ãƒ‰ã‚’å¼•ç”¨ãƒ»æ”¹å¤‰ã—ãŸã‚‚ã®ã§ã™ã€‚  
**æ–°æ©Ÿèƒ½**: DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãª ImageNet å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

## ğŸš€ ä¸»ãªç‰¹å¾´ãƒ»æ”¹è‰¯ç‚¹

- **DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ**: ãƒ­ãƒ¼ã‚«ãƒ«ã« ImageNet ã‚’ä¿å­˜ã›ãšã«å­¦ç¿’å¯èƒ½
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ¶ˆè²»ã‚¼ãƒ­**: å¾“æ¥ 150GB+å¿…è¦ã ã£ãŸ ImageNet ãŒä¸è¦
- **Colab æœ€é©åŒ–**: Google Drive ã®å®¹é‡åˆ¶é™ã‚’å›é¿
- **ç°¡å˜ãªã‚µãƒ–ã‚»ãƒƒãƒˆèª¿æ•´**: å¼•æ•° 1 ã¤ã§ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¤‰æ›´å¯èƒ½
- **æ—¢å­˜ã‚³ãƒ¼ãƒ‰äº’æ›æ€§**: å¾“æ¥ã®ä½¿ã„æ–¹ã‚‚ãã®ã¾ã¾åˆ©ç”¨å¯èƒ½

---

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### æ–¹æ³• 1: conda ç’°å¢ƒï¼ˆæ¨å¥¨ï¼‰

```bash
conda env create -f environment.yml
conda activate instantpure
```

### æ–¹æ³• 2: pip

```bash
pip install -r requirements.txt
```

### æ–¹æ³• 3: å€‹åˆ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆColab ç­‰ï¼‰

```bash
pip install deeplake torch torchvision diffusers transformers peft accelerate
```

---

## ğŸ”¥ ä½¿ç”¨æ–¹æ³•

### 1. DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç‰ˆï¼ˆæ¨å¥¨ï¼‰

ãƒ­ãƒ¼ã‚«ãƒ«ã« ImageNet ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚

```bash
# 40,000ã‚µãƒ³ãƒ—ãƒ«ã§LoRAå­¦ç¿’
python train_lora.py
    --use_deeplake
    --deeplake_subset 40000
    --train_batch_size 32
    --learning_rate 1e-4
    --output_dir ./output
```

### 2. å¾“æ¥ç‰ˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

`data/image_net/` ã« ImageNet ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚

```bash
# å¾“æ¥ã®æ–¹æ³•
python train_lora.py
    --max_train_samples 40000
    --train_batch_size 32
    --learning_rate 1e-4
    --output_dir ./output
```

### 3. ãƒ—ãƒ­ã‚°ãƒ©ãƒ å†…ã§ã®ä½¿ç”¨ä¾‹

```python
from dataset import get_dataset

# DeepLakeç‰ˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
dataloader = get_dataset(
    "imagenet",
    "train",
    use_deeplake=True,
    deeplake_subset=40000
)

# å¾“æ¥ç‰ˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
dataset = get_dataset("imagenet", "train", use_deeplake=False)
```

---

## âš™ï¸ å¼•æ•°ãƒ»ã‚ªãƒ—ã‚·ãƒ§ãƒ³

### DeepLake é–¢é€£ã®æ–°è¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| å¼•æ•°                | èª¬æ˜                          | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |
| ------------------- | ----------------------------- | ------------ |
| `--use_deeplake`    | DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ | `False`      |
| `--deeplake_subset` | ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°            | `40000`      |

### å¾“æ¥ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| å¼•æ•°                  | èª¬æ˜                                 |
| --------------------- | ------------------------------------ |
| `--max_train_samples` | ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆã§ã®ã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™ |
| `--train_batch_size`  | ãƒãƒƒãƒã‚µã‚¤ã‚º                         |
| `--learning_rate`     | å­¦ç¿’ç‡                               |
| `--output_dir`        | å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª                     |

---

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| é …ç›®               | **DeepLake ç‰ˆ**    | **å¾“æ¥ç‰ˆ**                  |
| ------------------ | ------------------ | --------------------------- |
| **äº‹å‰æº–å‚™**       | ãªã—               | ImageNet ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å±•é–‹ |
| **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ¶ˆè²»** | 0GB                | 150GB+                      |
| **åˆå›å®Ÿè¡Œ**       | ã™ãé–‹å§‹           | ãƒ‡ãƒ¼ã‚¿æº–å‚™å¾Œã«é–‹å§‹          |
| **ã‚µãƒ–ã‚»ãƒƒãƒˆå¤‰æ›´** | å¼•æ•°å¤‰æ›´ã®ã¿       | ãƒ‡ãƒ¼ã‚¿å†æº–å‚™ãŒå¿…è¦          |
| **Colab å¯¾å¿œ**     | âœ… å¿«é©            | âŒ Drive å®¹é‡ä¸è¶³           |
| **å­¦ç¿’é€Ÿåº¦**       | é«˜é€Ÿï¼ˆæœ€é©åŒ–æ¸ˆã¿ï¼‰ | ãƒ‡ã‚£ã‚¹ã‚¯ I/O ä¾å­˜           |

---

## ğŸ”§ å‹•ä½œç¢ºèªãƒ»ãƒ†ã‚¹ãƒˆ

```bash
# DeepLakeã®å‹•ä½œç¢ºèª
python test/test_deeplake_load.py

# å°è¦æ¨¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python train_lora.py --use_deeplake --deeplake_subset 1000 --max_train_steps 10
```

---

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### DeepLake ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªã„

```bash
pip install --upgrade pip
pip install deeplake
```

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼

DeepLake ã¯åˆå›å®Ÿè¡Œæ™‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚å®‰å®šã—ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

### ãƒ¡ãƒ¢ãƒªä¸è¶³

```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
python train_lora.py --use_deeplake --train_batch_size 16

# ã‚µãƒ–ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
python train_lora.py --use_deeplake --deeplake_subset 20000
```

### conda ç’°å¢ƒä½œæˆã‚¨ãƒ©ãƒ¼

```bash
# pandas ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç«¶åˆã®å ´åˆ
conda env create -f environment.yml --force
```

---

## ğŸ”„ äº’æ›æ€§

æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¯**ä¸€åˆ‡å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“**ã€‚`--use_deeplake`ãƒ•ãƒ©ã‚°ã‚’æŒ‡å®šã—ãªã„é™ã‚Šã€å¾“æ¥é€šã‚Šã®å‹•ä½œã‚’ã—ã¾ã™ã€‚

```bash
# å¾“æ¥ç‰ˆï¼ˆå¤‰æ›´ãªã—ï¼‰
python train_lora.py --max_train_samples 10000

# DeepLakeç‰ˆï¼ˆæ–°æ©Ÿèƒ½ï¼‰
python train_lora.py --use_deeplake --deeplake_subset 10000
```

---

## ğŸ”‘ ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®šæ–¹æ³•

#### Hugging Face Hub ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³

Stable Diffusion ãªã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€Hugging Face ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ã§ã™ã€‚

1. [Hugging Face ã®ãƒˆãƒ¼ã‚¯ãƒ³ç™ºè¡Œãƒšãƒ¼ã‚¸](https://huggingface.co/settings/tokens)ã§ã€ŒReadã€æ¨©é™ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
2. `.zshrc`ï¼ˆã¾ãŸã¯`.bashrc`ï¼‰ã«ä»¥ä¸‹ã‚’è¿½è¨˜ã—ã€æ¯å›è‡ªå‹•ã§è¨­å®šã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```sh
export HUGGINGFACE_TOKEN=hf_xxx...  # ã‚ãªãŸã®ãƒˆãƒ¼ã‚¯ãƒ³
```

è¨­å®šå¾Œã¯æ–°ã—ã„ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ãã‹ã€`source ~/.zshrc` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

#### DeepLake ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³

DeepLake ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å ´åˆã‚‚ã€DeepLake ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚

1. [DeepLake ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒšãƒ¼ã‚¸](https://app.deeplake.ai/)ã§ API ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
2. `.zshrc`ï¼ˆã¾ãŸã¯`.bashrc`ï¼‰ã«ä»¥ä¸‹ã‚’è¿½è¨˜ã—ã¾ã™ã€‚

```sh
export ACTIVELOOP_TOKEN=your_deeplake_token
```

åŒæ§˜ã«ã€è¨­å®šå¾Œã¯æ–°ã—ã„ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ãã‹ã€`source ~/.zshrc` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ã“ã‚Œã§æ¯å›æ‰‹å‹•ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã›ãšã«æ¸ˆã¿ã¾ã™ã€‚

---

## ğŸ“„ è«–æ–‡ãƒ»å¼•ç”¨

ã‚ªãƒªã‚¸ãƒŠãƒ«è«–æ–‡: [arXiv:2408.17064](https://arxiv.org/abs/2408.17064)

```bibtex
@article{instantpure2024,
  title={InstantPure: ...},
  author={...},
  journal={arXiv preprint arXiv:2408.17064},
  year={2024}
}
```

---

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

```
Copyright 2025 The HuggingFace Inc. team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

This code is modified from InstantPure (https://github.com/antony090/InstantPure),
which is modified on top of latent-consistency-model
(https://github.com/luosiallen/latent-consistency-model).
```

## ä½¿ã„æ–¹

- ã“ã“ã«ä½¿ã„æ–¹ã‚’è‡ªç”±ã«è¨˜è¼‰ã—ã¾ã™ã€‚

---

## æ”¹å¤‰

## DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç‰ˆ ImageNet

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€å¾“æ¥ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆ ImageNet ã«åŠ ãˆã¦ã€DeepLake ã‚’ä½¿ã£ãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç‰ˆ ImageNet ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

### ãƒ¡ãƒªãƒƒãƒˆ

- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ¶ˆè²»é‡**: 0GBï¼ˆå¾“æ¥ç‰ˆã¯ 150GB+ï¼‰
- **äº‹å‰æº–å‚™æ™‚é–“**: 0 åˆ†ï¼ˆå¾“æ¥ç‰ˆã¯æ•°æ™‚é–“ã€œæ•°æ—¥ï¼‰
- **ã‚µãƒ–ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºèª¿æ•´**: ç°¡å˜ï¼ˆå¼•æ•° 1 ã¤ã§å¤‰æ›´å¯èƒ½ï¼‰
- **Colab å¯¾å¿œ**: Google Drive ã®å®¹é‡åˆ¶é™ã«æ‚©ã¾ã•ã‚Œãªã„

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install deeplake

# ã¾ãŸã¯ã€condaç’°å¢ƒã‚’ä½¿ç”¨
conda env create -f environment.yml
conda activate research
```

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```python
# dataset.py ã‚’ä½¿ã£ã¦ DeepLake ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
from dataset import get_dataset

# DeepLakeç‰ˆï¼ˆ40,000ã‚µãƒ³ãƒ—ãƒ«ï¼‰
train_dataloader = get_dataset(
    "imagenet",
    "train",
    use_deeplake=True,
    deeplake_subset=40000
)

# å¾“æ¥ç‰ˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
train_dataset = get_dataset("imagenet", "train", use_deeplake=False)
```

### 2. å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã®ä½¿ç”¨

```bash
# DeepLakeã‚’ä½¿ç”¨ã—ã¦40,000ã‚µãƒ³ãƒ—ãƒ«ã§å­¦ç¿’
python train_lora.py \
    --use_deeplake \
    --deeplake_subset 40000 \
    --train_batch_size 32 \
    --learning_rate 1e-4

# å¾“æ¥ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆã§ã®å­¦ç¿’
python train_lora.py \
    --max_train_samples 40000 \
    --train_batch_size 32 \
    --learning_rate 1e-4
```

### 3. ã‚µãƒ³ãƒ—ãƒ«ã®å‹•ä½œç¢ºèª

```bash
# DeepLakeã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python test/test_deeplake_load.py
```

## å¼•æ•°ã®èª¬æ˜

### DeepLake é–¢é€£ã®æ–°ã—ã„å¼•æ•°

- `--use_deeplake`: DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹
- `--deeplake_subset`: ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 40,000ï¼‰

### å¾“æ¥ã®å¼•æ•°ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆï¼‰

- `--max_train_samples`: ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ã®ä¸Šé™
- ãƒ‡ãƒ¼ã‚¿ã¯ `data/image_net/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰èª­ã¿è¾¼ã¿

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| é …ç›®               | DeepLake ç‰ˆ        | ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆ          |
| ------------------ | ------------------ | --------------------------- |
| **äº‹å‰æº–å‚™**       | ãªã—               | ImageNet ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å±•é–‹ |
| **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**     | 0GB                | 150GB+                      |
| **åˆå›å®Ÿè¡Œ**       | ã™ãé–‹å§‹           | ãƒ‡ãƒ¼ã‚¿æº–å‚™å¾Œã«é–‹å§‹          |
| **ã‚µãƒ–ã‚»ãƒƒãƒˆå¤‰æ›´** | å¼•æ•°å¤‰æ›´ã®ã¿       | ãƒ‡ãƒ¼ã‚¿å†æº–å‚™ãŒå¿…è¦          |
| **å­¦ç¿’é€Ÿåº¦**       | é«˜é€Ÿï¼ˆæœ€é©åŒ–æ¸ˆã¿ï¼‰ | ãƒ‡ã‚£ã‚¹ã‚¯ I/O ä¾å­˜           |

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### DeepLake ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªã„å ´åˆ

```bash
pip install --upgrade pip
pip install deeplake
```

### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å ´åˆ

DeepLake ã¯åˆå›å®Ÿè¡Œæ™‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚å®‰å®šã—ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å ´åˆ

```python
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
python train_lora.py --use_deeplake --train_batch_size 16

# ã¾ãŸã¯ã‚µãƒ–ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
python train_lora.py --use_deeplake --deeplake_subset 20000
```

## å¾“æ¥ç‰ˆã¨ã®äº’æ›æ€§

æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¯ä¸€åˆ‡å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`--use_deeplake` ãƒ•ãƒ©ã‚°ã‚’æŒ‡å®šã—ãªã„é™ã‚Šã€å¾“æ¥é€šã‚Šã®å‹•ä½œã‚’ã—ã¾ã™ã€‚

```bash
# å¾“æ¥ç‰ˆï¼ˆå¤‰æ›´ãªã—ï¼‰
python train_lora.py --max_train_samples 10000

# DeepLakeç‰ˆï¼ˆæ–°æ©Ÿèƒ½ï¼‰
python train_lora.py --use_deeplake --deeplake_subset 10000
```

### ã©ã®ã‚ˆã†ãªä¿®æ­£ã‚’ã—ãŸã‹

1. **DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®è¿½åŠ **

   - dataset.py ã« DeepLake ã‹ã‚‰ ImageNet ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆä¾‹: `_imagenet_deeplake`ï¼‰ã‚’è¿½åŠ ã€‚
   - `get_dataset` é–¢æ•°ã« `use_deeplake`ãƒ»`deeplake_subset` å¼•æ•°ã‚’è¿½åŠ ã—ã€DeepLake åˆ©ç”¨æ™‚ã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° DataLoader ã‚’è¿”ã™ã‚ˆã†ã«ã—ãŸã€‚
   - æ—¢å­˜ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆ ImageNet ã®ã‚³ãƒ¼ãƒ‰ã¯ãã®ã¾ã¾æ®‹ã—ã€äº’æ›æ€§ã‚’ç¶­æŒã€‚

2. **å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã® DeepLake å¯¾å¿œ**

   - train_lora.py ã§ `--use_deeplake` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å—ã‘å–ã‚Šã€DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‹å¾“æ¥ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸã€‚
   - `--deeplake_subset` ã§ã‚µãƒ–ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã‚‚æŒ‡å®šå¯èƒ½ã€‚

3. **ä¾å­˜é–¢ä¿‚ã®è¿½åŠ **

   - requirements.txt ã¨ environment.yml ã« `deeplake` ã‚’è¿½åŠ ã€‚

4. **ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è¿½åŠ **

   - test_deeplake_load.py ã‚’è¿½åŠ ã—ã€DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®å‹•ä½œç¢ºèªãŒã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚

5. **å¼•æ•°ãƒ‘ãƒ¼ã‚µã®æ‹¡å¼µ**
   - get_args.py ã« `--use_deeplake` ã¨ `--deeplake_subset` ã‚’è¿½åŠ ã€‚

---

### README ã® DeepLake æ§‹æˆæ¡ˆ

#### 1. æ¦‚è¦ãƒ»ç‰¹å¾´

- æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯å¾“æ¥ã®ãƒ­ãƒ¼ã‚«ãƒ« ImageNet ã«åŠ ãˆã€DeepLake ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° ImageNet ã‚’ã‚µãƒãƒ¼ãƒˆ
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ¶ˆè²»ã‚¼ãƒ­ã€Colab ã§ã‚‚å¿«é©ã€ã‚µãƒ–ã‚»ãƒƒãƒˆã‚‚ç°¡å˜

#### 2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

- pip/conda ä¸¡å¯¾å¿œ
- `deeplake` ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ˜è¨˜

#### 3. ä½¿ã„æ–¹

- åŸºæœ¬çš„ãªä½¿ã„æ–¹ï¼ˆ`get_dataset` ã®ä¾‹ï¼‰
- å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã®ä½¿ã„åˆ†ã‘ï¼ˆ`--use_deeplake` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆtest_deeplake_load.pyï¼‰

#### 4. å¼•æ•°ãƒ»ã‚ªãƒ—ã‚·ãƒ§ãƒ³

- DeepLake ç”¨æ–°è¦å¼•æ•°ï¼ˆ`--use_deeplake`, `--deeplake_subset`ï¼‰
- å¾“æ¥ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç”¨å¼•æ•°

#### 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

- è¡¨å½¢å¼ã§ DeepLake ã¨ãƒ­ãƒ¼ã‚«ãƒ«ã®é•ã„ã‚’æ˜ç¤º

#### 6. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

- DeepLake ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯/ãƒ¡ãƒ¢ãƒªå•é¡Œ

#### 7. äº’æ›æ€§

- æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¯ãã®ã¾ã¾å‹•ä½œ
- DeepLake ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šæ™‚ã®ã¿æœ‰åŠ¹

#### 8. è«–æ–‡ãƒ»å¼•ç”¨

- ã‚ªãƒªã‚¸ãƒŠãƒ«è«–æ–‡ã‚„å¼•ç”¨ä¾‹
